# -*- coding: utf-8 -*-
"""GUI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EBn7gjR1hwViacbvEfkTLb5CuK59pAIG
"""

import os

import tensorflow as tf
from tensorflow.keras.models import load_model
import numpy as np

!pip install -q streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

import streamlit as st
import numpy as np
from PIL import Image
import tensorflow as tf
import cv2

from google.colab import drive
drive.mount('/content/drive')

from keras import models

loded_model = load_model("/content/AlexNet_500Epochs.h5")

loded_model.summary()

from google.colab import files

IMAGE_SIZE=256
BATCH_SIZE=32
CHANNELS=3
# EPOCHS=100

images_dataset=tf.keras.preprocessing.image_dataset_from_directory(
 '/content/drive/MyDrive/thyroid/test',
 shuffle=True,
 image_size=(IMAGE_SIZE,IMAGE_SIZE),
 batch_size=BATCH_SIZE,
)

class_names=images_dataset.class_names
class_names

#exploring the dataset
for image_batch, label_batch in images_dataset.take(1):
    print(image_batch.shape)
    print(label_batch.numpy())

def get_dataset_partitions_tf(ds,train_split=0.8, val_split=0.1, test_split=0.1,shuffle=True, shuffle_size=10000):
    ds_size=len(ds)
    if shuffle:
        ds=ds.shuffle(shuffle_size,seed=12)

    train_size= int(train_split* ds_size)
    val_size=int(val_split* ds_size)

    train_ds=ds.take(train_size)

    val_ds=ds.skip(train_size).take(val_size)

    test_ds=ds.skip(train_size).skip(val_size)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds=get_dataset_partitions_tf(images_dataset)

print(len(train_ds),len(val_ds),len(test_ds))

train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

#Write a function for interference

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

import matplotlib.pyplot as plt

# Now run inference on few sample images
pred = []
act = []
plt.figure(figsize=(15, 15))
for images, labels in test_ds.take(1):
    for i in range(25):
        ax = plt.subplot(5, 5, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))

        predicted_class, confidence = predict(loded_model, images[i].numpy())
        actual_class = class_names[labels[i]]

        pred.append(predicted_class)
        act.append(actual_class)

        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")

        plt.axis("off")

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(act,pred)

tn,fp,fn,tp = cm.ravel()

print(tp,fn,tn,fp)

cm

# Streamlit app
st.title('Thyroid Malignancy Detection')
!npm install localtunnel



streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]
DeltaGenerator()

st.subheader('Hybrid model Detection')
uploaded_image_thyroid = st.file_uploader('Upload an image of a thyroid', type=['jpg', 'jpeg', 'png'])

if uploaded_image_thyroid is not None:
    image = Image.open(uploaded_image_thyroid)
    st.image(image, caption='Uploaded Image (Thyroid)', use_column_width=True)

# Make predictions for Malignancy
    prediction_Malignancy = predict_malignancy(np.array(image))
    disease_class_Malignancy = np.argmax(prediction_Malignancy)
    classes_Malignancy = ['Malignancy___Benign', 'Malignancy___Malignant']
    st.write(f'Predicted class (Malignancy): {classes_Malignancy[disease_class_Malignancy]}')

    st.write('Class probabilities (Malignancy):')
    for i, class_name in enumerate(classes_Malignancy):
        st.write(f'{class_name}: {prediction_Malignancy[0][i]:.4f}')

